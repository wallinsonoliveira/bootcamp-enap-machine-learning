{"cells":[{"cell_type":"markdown","metadata":{"id":"NWtgMRHeVmTV"},"source":["## Carregar bibliotecas"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1728570018866,"user":{"displayName":"thiago hendler","userId":"07401704367017023586"},"user_tz":180},"id":"T9G50UffLUc4"},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from tensorflow import keras\n","from tensorflow.keras.utils import FeatureSpace\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["placa                                 0\n","h_perm_front                          0\n","anoModelo                             1\n","categoria                             1\n","cor                                   1\n","dataEmissaoCrv                        1\n","descricaoTipoDocumentoProprietario    1\n","marcaModelo                           1\n","municipioEmplacamento                 1\n","tipo                                  1\n","ufEmplacamento                        1\n","descricao                             0\n","ilicito                               0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Carregando o DataFrame (substitua 'seu_dataframe.csv' pelo nome do seu arquivo)\n","df = pd.read_csv('/Users/thiagohendler/Documents/Bootcamp Machine Learning - ENAP/CODIGO/equipe_8-2.csv', encoding='latin1')\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["df = df.dropna()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["df.rename(columns={'h_perm_front': 'tempofronteira',\n","                   'anoModelo': 'anomodelo',\n","                   'dataEmissaoCrv': 'dataemissaocrv',\n","                   'descricaoTipoDocumentoProprietario': 'tipodocumentoproprietario',\n","                   'municipioEmplacamento': 'municipioemplacamento',\n","                   'ufEmplacamento': 'ufemplacamento',\n","                   'descricao': 'consulta_res',\n","                   'ilicito': 'target'\n","                   }, inplace=True)\n","df[['marca', 'modelo']] = df['marcaModelo'].str.split('/', expand=True)\n","\n","# Converter para data\n","df['dataemissaocrv'] = pd.to_datetime(df['dataemissaocrv'], unit='ms')\n","\n","#Adicionar essa coluna gera uma colinariedade com a coluna dataemissaocrv\n","df['dataemissaocrv'] = df['dataemissaocrv'].dt.year\n","\n","df['anomodelo'] = df['anomodelo'].astype(int)\n","\n","df['unicodono'] = df['dataemissaocrv'] <= df['anomodelo']\n","\n","df['tempofronteira'] = df['tempofronteira'].astype(int)\n","df['anomodelo'] = df['anomodelo'].astype(int)\n","df['dataemissaocrv'] = df['dataemissaocrv'].astype(int)\n","\n","# Apagar colunas não utlizadas mais\n","df = df.drop('placa', axis=1)\n","df = df.drop('marcaModelo', axis=1)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Usando 596 amostras para o treino e 149 para validação\n"]}],"source":["X = df.drop(['target'], axis=1)\n","y = df['target'].astype(int)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","print(\n","    \"Usando %d amostras para o treino e %d para validação\"\n","    % (len(X_train), len(X_test))\n",")"]},{"cell_type":"code","execution_count":146,"metadata":{},"outputs":[],"source":["def dataframe_to_dataset(X, y):\n","    # Combina X e y em um DataFrame temporário\n","    df = X.copy()\n","    df['target'] = y\n","\n","    labels = df.pop(\"target\")\n","    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n","    ds = ds.shuffle(buffer_size=len(df))\n","    return ds"]},{"cell_type":"code","execution_count":147,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'tempofronteira': <tf.Tensor: shape=(), dtype=int64, numpy=23>, 'anomodelo': <tf.Tensor: shape=(), dtype=int64, numpy=2020>, 'categoria': <tf.Tensor: shape=(), dtype=string, numpy=b'PARTICULAR'>, 'cor': <tf.Tensor: shape=(), dtype=string, numpy=b'VERMELHA'>, 'dataemissaocrv': <tf.Tensor: shape=(), dtype=int64, numpy=2019>, 'tipodocumentoproprietario': <tf.Tensor: shape=(), dtype=string, numpy=b'CPF'>, 'municipioemplacamento': <tf.Tensor: shape=(), dtype=string, numpy=b'PONTA GROSSA'>, 'tipo': <tf.Tensor: shape=(), dtype=string, numpy=b'AUTOMOVEL'>, 'ufemplacamento': <tf.Tensor: shape=(), dtype=string, numpy=b'PR'>, 'consulta_res': <tf.Tensor: shape=(), dtype=string, numpy=b'N\\xc3\\xa3o h\\xc3\\xa1 restri\\xc3\\xa7\\xc3\\xb5es para este ve\\xc3\\xadculo no DENATRAN BASE 24h/7d.'>, 'marca': <tf.Tensor: shape=(), dtype=string, numpy=b'RENAULT'>, 'modelo': <tf.Tensor: shape=(), dtype=string, numpy=b'KWID ZEN 10MT'>, 'unicodono': <tf.Tensor: shape=(), dtype=bool, numpy=True>}\n","tf.Tensor(0, shape=(), dtype=int64)\n"]}],"source":["# Transformando os dados de treino e teste em datasets\n","train_ds = dataframe_to_dataset(X_train, y_train)\n","val_ds = dataframe_to_dataset(X_test, y_test)\n","\n","# Verifique se os datasets foram criados corretamente\n","for features_batch, label_batch in train_ds.take(1):\n","    print(features_batch)\n","    print(label_batch)\n"]},{"cell_type":"code","execution_count":148,"metadata":{},"outputs":[],"source":["feature_space = FeatureSpace(\n","    features={\n","        # Categorical features encoded as integers\n","        \"unicodono\": \"integer_categorical\",\n","        # Categorical feature encoded as string\n","        \"categoria\": \"string_categorical\",\n","        \"tipodocumentoproprietario\": \"string_categorical\",\n","        \"cor\": \"string_categorical\",\n","        \"tipo\": \"string_categorical\",\n","        \"ufemplacamento\": \"string_categorical\",\n","        \"consulta_res\": \"string_categorical\",\n","        \"marca\": \"string_categorical\",\n","        \"modelo\": \"string_categorical\",\n","        \"municipioemplacamento\": \"string_categorical\",\n","        # Numerical features to discretize\n","        \"anomodelo\": \"float_discretized\",\n","        \"dataemissaocrv\": \"float_discretized\",\n","        # Numerical features to normalize\n","        \"tempofronteira\": \"float_normalized\",\n","    },\n","    # We create additional features by hashing\n","    # value co-occurrences for the\n","    # following groups of categorical features.\n","    crosses=[(\"categoria\", \"tipodocumentoproprietario\"), (\"ufemplacamento\", \"tipodocumentoproprietario\"),(\"tipo\", \"tipodocumentoproprietario\")],\n","    # The hashing space for these co-occurrences\n","    # wil be 32-dimensional.\n","    crossing_dim=32,\n","    # Our utility will one-hot encode all categorical\n","    # features and concat all features into a single\n","    # vector (one vector per sample).\n","    output_mode=\"concat\",\n",")"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[],"source":["train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n","feature_space.adapt(train_ds_with_no_labels)"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[],"source":["preprocessed_train_ds = train_ds.map(\n","    lambda x, y: ([feature_space(x)], tf.expand_dims(y, axis=-1)), num_parallel_calls=tf.data.AUTOTUNE\n",")\n","preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n","\n","preprocessed_val_ds = val_ds.map(\n","    lambda x, y: ([feature_space(x)], tf.expand_dims(y, axis=-1)), num_parallel_calls=tf.data.AUTOTUNE\n",")\n","preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"name":"stdout","output_type":"stream","text":["596/596 - 4s - 7ms/step - accuracy: 0.6661 - loss: 0.6245 - val_accuracy: 0.6980 - val_loss: 0.5914\n","Epoch 2/20\n","596/596 - 1s - 2ms/step - accuracy: 0.8104 - loss: 0.4327 - val_accuracy: 0.7651 - val_loss: 0.5403\n","Epoch 3/20\n","596/596 - 3s - 5ms/step - accuracy: 0.8607 - loss: 0.3600 - val_accuracy: 0.7718 - val_loss: 0.5379\n","Epoch 4/20\n","596/596 - 2s - 4ms/step - accuracy: 0.8876 - loss: 0.2807 - val_accuracy: 0.7315 - val_loss: 0.5316\n","Epoch 5/20\n","596/596 - 5s - 8ms/step - accuracy: 0.9128 - loss: 0.2425 - val_accuracy: 0.7785 - val_loss: 0.5420\n","Epoch 6/20\n","596/596 - 4s - 6ms/step - accuracy: 0.9178 - loss: 0.1951 - val_accuracy: 0.7987 - val_loss: 0.5628\n","Epoch 7/20\n","596/596 - 2s - 3ms/step - accuracy: 0.9362 - loss: 0.1706 - val_accuracy: 0.8054 - val_loss: 0.5710\n","Epoch 8/20\n","596/596 - 2s - 3ms/step - accuracy: 0.9463 - loss: 0.1462 - val_accuracy: 0.8054 - val_loss: 0.5974\n","Epoch 9/20\n","596/596 - 6s - 9ms/step - accuracy: 0.9530 - loss: 0.1273 - val_accuracy: 0.8121 - val_loss: 0.6046\n","Epoch 10/20\n","596/596 - 3s - 4ms/step - accuracy: 0.9614 - loss: 0.1007 - val_accuracy: 0.8054 - val_loss: 0.6325\n","Epoch 11/20\n","596/596 - 4s - 7ms/step - accuracy: 0.9799 - loss: 0.0858 - val_accuracy: 0.8121 - val_loss: 0.6755\n","Epoch 12/20\n","596/596 - 3s - 4ms/step - accuracy: 0.9765 - loss: 0.0852 - val_accuracy: 0.8188 - val_loss: 0.6860\n","Epoch 13/20\n","596/596 - 3s - 5ms/step - accuracy: 0.9832 - loss: 0.0597 - val_accuracy: 0.8121 - val_loss: 0.7450\n","Epoch 14/20\n","596/596 - 2s - 4ms/step - accuracy: 0.9899 - loss: 0.0535 - val_accuracy: 0.8188 - val_loss: 0.7193\n","Epoch 15/20\n","596/596 - 2s - 3ms/step - accuracy: 0.9883 - loss: 0.0450 - val_accuracy: 0.8255 - val_loss: 0.7568\n","Epoch 16/20\n","596/596 - 2s - 3ms/step - accuracy: 0.9883 - loss: 0.0455 - val_accuracy: 0.8389 - val_loss: 0.7829\n","Epoch 17/20\n","596/596 - 2s - 3ms/step - accuracy: 0.9883 - loss: 0.0356 - val_accuracy: 0.8121 - val_loss: 0.8540\n","Epoch 18/20\n","596/596 - 2s - 3ms/step - accuracy: 0.9883 - loss: 0.0389 - val_accuracy: 0.8054 - val_loss: 0.9200\n","Epoch 19/20\n","596/596 - 2s - 3ms/step - accuracy: 0.9933 - loss: 0.0291 - val_accuracy: 0.8054 - val_loss: 0.8747\n","Epoch 20/20\n","596/596 - 1s - 3ms/step - accuracy: 0.9883 - loss: 0.0435 - val_accuracy: 0.8121 - val_loss: 0.9287\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x16c65d040>"]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["\n","# 2. Adaptar o FeatureSpace\n","# Obter as entradas e características codificadas do FeatureSpace\n","dict_inputs = feature_space.get_inputs()\n","encoded_features = feature_space.get_encoded_features()\n","\n","# Criar a arquitetura do modelo\n","x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)  # Camada oculta\n","x = keras.layers.Dropout(0.5)(x)  # Camada de dropout para regularização\n","predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)  # Camada de saída\n","\n","# 6. Criar o modelo de treinamento\n","training_model = keras.Model(inputs=[encoded_features], outputs=predictions)  # Note o uso de uma lista\n","\n","# 7. Compilar o modelo\n","training_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","\n","inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)\n","\n","# Treinamento do modelo\n","training_model.fit(\n","    preprocessed_train_ds,  # Conjunto de dados de treinamento pré-processados\n","    epochs=20,  # Número de épocas\n","    validation_data=preprocessed_val_ds,  # Conjunto de dados de validação pré-processados\n","    verbose=2,  # Nível de verbosidade\n",")"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["149/149 - 0s - 904us/step - accuracy: 0.8121 - loss: 0.9287\n","Test loss: 0.9287\n","Test accuracy: 0.8121\n"]}],"source":["# Avaliação do modelo nos dados de teste\n","test_loss, test_accuracy = training_model.evaluate(preprocessed_val_ds, verbose=2)\n","\n","print(f'Test loss: {test_loss:.4f}')\n","print(f'Test accuracy: {test_accuracy:.4f}')\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n","[[0.2759936 ]\n"," [0.80588496]\n"," [0.19188108]\n"," [0.9091081 ]\n"," [0.3591524 ]]\n"]}],"source":["# Fazer previsões nos dados de teste\n","predictions = training_model.predict(preprocessed_val_ds)\n","\n","# Exibir algumas previsões\n","print(predictions[:5])  # Mostra as primeiras 5 previsões\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1ijz9ekvo8w2MXEGiWdJxz8NfiBpvL1Ix","timestamp":1728070423554},{"file_id":"1LPcz6ECrnqsJoiHVlCzG7T00yHnnALiX","timestamp":1728062735631}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
